<style>
 td {
  width: 150px;
}
</style>
---
title: CS 520 Final Project
author: Krupa Nagori
output: html_document
---
#### Abstract
#### Introduction
  The cost of healthcare is a common conversation in the modern household and more so in recent times due to the 2020 pandemic. A large part of these discussions often circles around age and pre-existing conditions. A multitude of studies suggest that as age increases there is a decline in health from cognitive decline to decrease in physical activity (1). This would suggest that as people age their need for healthcare would increase as increased support would be needed to deal with increasing health concerns. However, generally as people approach older ages they also begin to enter retirement and rely upon social security and limited income. The goal of this paper is to develop and methodology to study population data to compare the cost of healthcare per person against the age of the person. 
  The methodology utilized in the project is to create functions to statistically analyze demgraphic data for healthcare cost against age. The functions are then implemented to generate a series of plots displaying the distribution of costs of healthcare spread across the age spectrum. These results are then cross validated utilizing residuals to determine the veracity of the data. The pooled residuals are graphed in qq plots to deermine if the residuals in each group are identically distrubted. Based on the results we see that healthcare costs increase by age even when excluding extreme data points. 
  The next steps based on this analysis would be to analyze the other demographic data contained in the data set to gain a bigger picture of age, income, and lifestyle costs as compared to healthcare costs. 

#### Methodology
The analysis requires 7 packages. ggplot2 is a tidyverse visualization package that is utilized here to generate the graphs. plyr is utilized to breakdown the demographic data set into necessary subsets. reshape2 is used in conjuction with plyr to shape the data into the necessary frame for implementation with the functions. boot, broom, splines and MASS are used for the statistical analysis portion of project and to graph the results. Lastly, the command `set.seed(x)`, where `x` is any number, fixes the random number generator to give the same output every time. This is to ensure that the cross validation results will be the same each time, since a random sample is taken.

```{r fig.width=8, fig.height=6, dpi=100, fig.align='center'}
#Preliminaries
#Install packages as needed to run analysis
list.of.packages <- c("ggplot2", "plyr", "reshape2", "splines", "boot", "MASS", "broom")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

#libraries
library(ggplot2)
library(plyr)
library(reshape2)
library(splines)
library(boot)
library(MASS)
library(broom)

#Random number generator with set to give the same output every time.
set.seed(1)
```
For the analysis three functions were created. The first function glm.cv.loop is used to take the imported data and create a fitted spline model. To ensure data accuracy within the function and that the data over or under fitted k-fold cross validation is built in to the function. K in this instance is mean to represent the number of groups the sample will be split into. Cross validation then uses the k number to resample and test the data. 
```{r fig.width=8, fig.height=6, dpi=100, fig.align='center'}
#Functions
glm.cv.loop = function(data, formula.text, DF.vector, K=10) {
# make sure boot library is loaded
require(boot) 
cv.scores = rep(0, times = length(DF.vector))
for (DF in DF.vector) {
# get the fitted model for current value of DF
spline.model = glm(as.formula(formula.text), data=data)
# run K-fold cross validation 
cv = cv.glm(data=data, glmfit=spline.model, K=K)
# extract the cross-validation score
cv.scores[DF] = cv$delta[1]
}
# make the plot
data.out = data.frame(df = DF.vector, cv.scores = cv.scores)
cv.plot = ggplot(data = data.out, mapping=aes(x=df, y=cv.scores)) + geom_point() + labs(x='df', title='Cross Validation Scores')
# return a list containing the scores and the plot
return( list(scores = cv.scores, plot = cv.plot))
}  
```
The second function Find.QQ used to find if the two sets of data contains a common distribution. The qq plots function is created to check the distribution of points. If the points results in a straight line distribution at about 45* and the points are near that the line the data contains a common distribution. If they do not fall on that line that means the data contains a skew.
```{r fig.width=8, fig.height=6, dpi=100, fig.align='center'}
Find.QQ = function(.data, column.name, y) {
# how many quantiles are we plotting?
n.pts = min( length(.data[, column.name]), length(y))
# which quantiles are we plotting?
probs = seq(from = 0, to = 1, length.out = n.pts)
# compute these quantiles for each group
q1 = quantile(.data[, column.name], probs= probs)
q2 = quantile(y, probs=probs )
# return them as a data frame
return( data.frame(q1 = q1, q2 = q2))
}

Pool.Residuals = function (data.augment, x, qvec = c(.05, .15, .5, .85, .95)) {
require(plyr)
require(reshape2)
# find the quantiles of the residuals
resid.quantile = quantile(x = data.augment$.resid, probs = qvec)
# add the quantiles of the residuals to the predicted trend
data.augment = mutate(data.augment, 
q1 = .fitted + resid.quantile[1],
q2 = .fitted + resid.quantile[2],                                      
q3 = .fitted + resid.quantile[3],                                      
q4 = .fitted + resid.quantile[4],              
q5 = .fitted + resid.quantile[5])
# combine all of the quantiles into one column for easier plotting:
data.melt = melt(data.augment, id.vars= x, measure.vars = c('q1', 'q2', 'q3', 'q4', 'q5'))
return( data.melt )
}
```

```{r fig.width=8, fig.height=6, dpi=100, fig.align='center'}

# The first step will be to load the data file. 
# The focus of the analysis will be to look at living costs when compared to age of the interviewee 

#Import the data file `midterm-dataset.csv`, which should be in the same directory as this markdown file (which should also be your working directory). It is a data frame of expenditures by household from the consumer expenditure survey
demographic_dataset = read.csv(file = 'dataset/midterm-dataset.csv', header = TRUE)

#Healthcare
#First create a simple lm with healthcare as a function of age.interviewee
agetohealthcost = lm(formula = healthcare ~ age.interviewee, data = demographic_dataset)
agetohealthcost
#from here plot the data to have a starting point
agetohealthcost.plot = ggplot(data=demographic_dataset, mapping=aes(x=age.interviewee, y=healthcare)) + geom_point()
agetohealthcost.plot + geom_smooth(method='lm') + 
labs(x = 'Interview Age', y='Healthcare')
# The resulting graph shows that the people of a younger age have lower cost of healthcare and as ages increase the healthcare costs appear to increase as well. 

#Here apply the qualifications
demographic_subset.1 <- demographic_dataset[which(demographic_dataset$healthcare > 1),]
demographic_subset <- demographic_subset.1[-which(demographic_subset.1$age.interviewee > 86),]
#Create a new plot based on the new data that will show the difference from before
agetohealthcost.subset.plot <- ggplot(data=demographic_subset, mapping=aes(x=age.interviewee, y=healthcare)) + geom_point()
agetohealthcost.subset.plot + geom_smooth(method='lm')+ 
labs(x = 'Interview Age', y='Healthcare')
#Removing the extremeties maintained a similar trend in terms of cost to age increase similarly


#Cross Validation
#This step uses a log to fit a natural spline to your data for cross validation. 
#Mutate to add the log to the dataframe
crossvalidation.subset = mutate(demographic_subset, log.healthcare = log(healthcare))
#Use the function given to us above
out = glm.cv.loop(crossvalidation.subset, formula.text = "log.healthcare ~ ns(age.interviewee, df=DF)", DF.vector = 1:30)

crossvalidationmodel = lm(formula = healthcare ~ age.interviewee, data = crossvalidation.subset)
#create a new subset for the s-l plot
ggplotcv.subset = augment(crossvalidationmodel, data=crossvalidation.subset)
#generate the s-l plot
ggplot(data = ggplotcv.subset, mapping=aes(x = .fitted, y = sqrt(abs(.resid)))) + geom_point(size = 1) + geom_smooth()

#Plot the residuals against the predicted values to see if they look identically distributed. Divide `age.interviewee` and `.fitted` into groups, and use quantile plots or QQ plots to see if the residuals in each group look identically distributed. Do they?

#generate a subset from the previous data use cut to group data
residuals.subset = mutate(ggplotcv.subset, pred = predict(crossvalidationmodel), resid = resid(crossvalidationmodel), age.interviewee.cat = cut_number(age.interviewee, n = 10))
residualsqq.subset = mutate(residuals.subset, pred = predict(crossvalidationmodel), resid = resid(crossvalidationmodel), fitted.cat = cut_number(.fitted, n = 10))

#plot each of groups to compare
ggplot(data = residualsqq.subset, mapping=aes(sample = resid, color = age.interviewee.cat)) + stat_qq(distribution=qunif) + labs(x = 'quantiles', y = 'residual log healthcare', title = 'Quantile Plot, Residual Log Healthcare')

ggplot(data = residualsqq.subset, mapping=aes(sample = resid, color = fitted.cat)) + stat_qq(distribution=qunif) + labs(x = 'quantiles', y = 'residual log healthcare', title = 'Quantile Plot, Residual Log Healthcare')
#Create qq plots to compare more clearly
QQ.df = ddply(residualsqq.subset, 'age.interviewee.cat', Find.QQ, column.name ="resid", y = residualsqq.subset$resid)
QQ2.df = ddply(residualsqq.subset, 'fitted.cat', Find.QQ, column.name = "resid", y = residualsqq.subset$resid)

ggplot(data = QQ.df, mapping=aes(x = q1, y = q2)) + geom_point() + geom_abline() + facet_wrap('age.interviewee.cat', nrow = 2) + labs(title='QQ Plot, grouped vs pooled residuals')

ggplot(data = QQ2.df, mapping=aes(x = q1, y = q2)) + geom_point() + geom_abline() + facet_wrap('fitted.cat', nrow = 2) + labs(title='QQ Plot, grouped vs pooled residuals')

#The QQ plot help signficantly in trying to see if the residuals in each group look identically distributed.Based on the plot generated the residuals in each group look identically distributed.
```
#### Results
#### Conclusion

Future work from this project would be to implement ther the methodology to further analyze different facets of the demographic data reusing the same functions against different pairings or groups. For work utilizing these scripts would be to compare average incomes groups against average healthcare costs grouped by age to determine if costs are affected by both age, income, and suggested potential access to healthcare. A second comparison would be to compare lifestyle from cost of housing to food and region of living to cost of healthcare. These additional facets wold provide greater context as cost of living varies from region to region but also overall household costs can create a more wholistic picture. 
#### References
1. Vaitkevicius, P V, et al. “Effects of Age and Aerobic Capacity on Arterial Stiffness in Healthy Adults.” Circulation, 1 Oct. 1993, www.ahajournals.org/doi/abs/10.1161/01.CIR.88.4.1456. 
2. 
