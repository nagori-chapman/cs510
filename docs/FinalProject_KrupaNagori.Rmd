<style>
 td {
  width: 150px;
}
</style>
---
title: CS 520 Final Project
author: Krupa Nagori
output: html_document
---
#### Introduction
  The cost of healthcare is a common conversation in the modern household and more so in recent times due to the 2020 pandemic. A large part of these discussions often circles around age and pre-existing conditions. A multitude of studies suggest that as age increases there is a decline in health from cognitive decline to decrease in physical activity (3,6). This would suggest that as people age their need for healthcare would increase as increased support would be needed to deal with increasing health concerns. However, generally as people approach older ages they also begin to enter retirement and rely upon social security and limited income. The goal of this paper is to develop and methodology to study population data to compare the cost of living and specifically the scope of this project is narrowed to healthcare per person against the age of the person. 
  The methodology utilized in the project is to create functions to statistically analyze demgraphic data for healthcare cost against age. The functions are then implemented to generate a series of plots displaying the distribution of costs of healthcare spread across the age spectrum. These results are then cross validated utilizing residuals to determine the veracity of the data. The pooled residuals are graphed in qq plots to deermine if the residuals in each group are identically distrubted. Based on the results we see that healthcare costs increase by age even when excluding extreme data points. 
  The next steps based on this analysis would be to analyze the other demographic data contained in the data set to gain a bigger picture of age, income, and lifestyle costs as compared to healthcare costs. 

#### Methodology and Results
The analysis requires 7 packages. ggplot2 is a tidyverse visualization package that is utilized here to generate the graphs. plyr is utilized to breakdown the demographic data set into necessary subsets. reshape2 is used in conjuction with plyr to shape the data into the necessary frame for implementation with the functions. boot, broom, splines and MASS are used for the statistical analysis portion of project and to graph the results. Lastly, the command `set.seed(x)`, where `x` is any number, fixes the random number generator to give the same output every time. This is to ensure that the cross validation results will be the same each time, since a random sample is taken.

```{r echo = FALSE,fig.width=8, fig.height=6, dpi=100, fig.align='center'}
#Preliminaries
#Install packages as needed to run analysis
list.of.packages <- c("ggplot2", "plyr", "reshape2", "splines", "boot", "MASS", "broom")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

#libraries
library(ggplot2)
library(plyr)
library(reshape2)
library(splines)
library(boot)
library(MASS)
library(broom)

#Random number generator with set to give the same output every time.
set.seed(1)
```
For the analysis three functions were created. The first function glm.cv.loop is used to take the imported data and create a fitted spline model. To ensure data accuracy within the function and that the data over or under fitted k-fold cross validation is built in to the function. K in this instance is mean to represent the number of groups the sample will be split into. Cross validation then uses the k number to resample and test the data. 
```{r echo = FALSE,fig.width=8, fig.height=6, dpi=100, fig.align='center'}
#Functions
glm.cv.loop = function(data, formula.text, DF.vector, K=10) {
  # make sure boot library is loaded
  require(boot) 
  cv.scores = rep(0, times = length(DF.vector))
  for (DF in DF.vector) {
  # get the fitted model for current value of DF
  spline.model = glm(as.formula(formula.text), data=data)
  # run K-fold cross validation 
  cv <- cv.glm(data=data, glmfit=spline.model, K=K)
  # extract the cross-validation score
  cv.scores[DF] = cv$delta[1]
}
# make the plot
data.out <- data.frame(df = DF.vector, cv.scores = cv.scores)
cv.plot <- ggplot(data = data.out, mapping=aes(x=df, y=cv.scores)) + geom_point() + labs(x='df', title='Cross Validation Scores')
# return a list containing the scores and the plot
return( list(scores = cv.scores, plot = cv.plot))
}  
```
The second function Find.QQ used to find if the two sets of data contains a common distribution. The qq plots function is created to check the distribution of points. If the points results in a straight line distribution at about 45* and the points are near that the line the data contains a common distribution. If they do not fall on that line that means the data contains a skew. This function is used in conjuction with the pool.residuals function to plot the residuals. 
```{r echo = FALSE,fig.width=8, fig.height=6, dpi=100, fig.align='center'}
Find.QQ <- function(.data, column.name, y) {
  # how many quantiles are we plotting?
  n.pts <- min( length(.data[, column.name]), length(y))
  # which quantiles are we plotting?
  probs = seq(from = 0, to = 1, length.out = n.pts)
  # compute these quantiles for each group
  q1 <- quantile(.data[, column.name], probs= probs)
  q2 <- quantile(y, probs=probs )
  # return them as a data frame
  return( data.frame(q1 = q1, q2 = q2))
}
```
The last function utilized is Pool.Residuals is a function used as a secondary check method in additionto cross validation. The function is used a regression method to create multiple quantiles of both grouped and pooled residuals to determine variance in the data. 
```{r echo = FALSE,fig.width=8, fig.height=6, dpi=100, fig.align='center'}
Pool.Residuals <- function (data.augment, x, qvec = c(.05, .15, .5, .85, .95)) {
  require(plyr)
  require(reshape2)
  # find the quantiles of the residuals
  resid.quantile <- quantile(x = data.augment$.resid, probs = qvec)
  # add the quantiles of the residuals to the predicted trend
  data.augment = mutate(data.augment, 
  q1 = .fitted + resid.quantile[1],
  q2 = .fitted + resid.quantile[2],                                      
  q3 = .fitted + resid.quantile[3],                                      
  q4 = .fitted + resid.quantile[4],              
  q5 = .fitted + resid.quantile[5])
  # combine all of the quantiles into one column for easier plotting:
  data.melt <- melt(data.augment, id.vars= x, measure.vars = c('q1', 'q2', 'q3', 'q4', 'q5'))
  return( data.melt )
}
```
The first step of starting the analysis is to the load the data. The dataset utilized in this project is a deemographic data set that breakdown information by factors such as age, income, cost of food, cost of healthcare, and etc. As mentioned above the focus of this analysis is the cost of healthcare as associated with age. The data is in a simple csv file and does contain a header therefore we use the read.csv function and set header = True so that it is included appropriately in the dataframe. 
```{r echo = FALSE,fig.width=8, fig.height=6, dpi=100, fig.align='center'}

# The first step will be to load the data file. 
# The focus of the analysis will be to look at healthcare costs when compared to age of the interviewee 

# Load the data file
demographic_dataset <- read.csv(file = '../dataset/midterm-dataset.csv', header = TRUE)
```
After the data has been imported lm is used to create a simple linear model. After the linear model as been created ggplot is used to create a graph of linear model. Doing this will provide a first picture of the data and give initial indication of extreme data points or trends to be aware of when qualifying the data. 
```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=8, fig.height=6, dpi=100, fig.align='center'}
agetohealthcost <- lm(formula = healthcare ~ age.interviewee, data = demographic_dataset)
#from here plot the data to have a starting point
agetohealthcost.plot <- ggplot(data=demographic_dataset, mapping=aes(x=age.interviewee, y=healthcare)) + geom_point()
agetohealthcost.plot + geom_smooth(method ='lm') + 
labs(x = 'Interview Age', y='Healthcare')
ggsave(agetohealthcost.plot, filename = "../results/agetohealthcost.png")
```
The resulting graph shows displays age on the x axis with healthcare on the y-axis. The graph shows that the people of a younger age have lower cost of healthcare and as ages increase the healthcare costs appear to increase as well. However, the graph also shows some outlier with a gap over the 86 and under 1. Removing these outliers and applying them as qualitification to create a subset would help to see if the trend is affected by the outliers. 

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=8, fig.height=6, dpi=100, fig.align='center'}

#Here apply the qualifications
demographic_subset.1 <- demographic_dataset[which(demographic_dataset$healthcare > 1),]
demographic_subset <- demographic_subset.1[-which(demographic_subset.1$age.interviewee > 86),]
#Create a new plot based on the new data that will show the difference from before
agetohealthcost.subset.plot <- ggplot(data=demographic_subset, mapping=aes(x=age.interviewee, y=healthcare)) + geom_point()
agetohealthcost.subset.plot + geom_smooth(method='lm')+ 
labs(x = 'Interview Age', y='Healthcare')
ggsave(agetohealthcost.plot, filename = "../results/agetohealthcost.png")
```
Removing the extremeties maintained a similar trend in terms of cost to age increase similarly. The plot mimics the first plot in that the interviewee of younger age lowers costs and number increases as age increases. However, there is an abrupt change in the distribution of expenditures at any particular age. The age of change is between 80 and 90. 
The next step is cross validation as mentioned above to ensure that linear model is fitted correctly using k-fold cross validation. The validation step uses the functions created above to accomplish the task.  For this cross validation a log or power transformation can be used to fit a natural spline to the data. In this case we utilized a log transformation. The s-1 plot is used to check if the variance of the rediuals is somewhatconstant as a function of predicted values.

```{r echo = FALSE,message = FALSE, warning = FALSE, fig.width=8, fig.height=6, dpi=100, fig.align='center'}
#Cross Validation
#This step uses a log to fit a natural spline to your data for cross validation. 
#Mutate to add the log to the dataframe
crossvalidation.subset <- mutate(demographic_subset, log.healthcare = log(healthcare))
#Use the function given to us above
out <- glm.cv.loop(crossvalidation.subset, formula.text = "log.healthcare ~ ns(age.interviewee, df = DF)", DF.vector = 1:30)

crossvalidationmodel <- lm(formula = healthcare ~ age.interviewee, data = crossvalidation.subset)
#create a new subset for the s-l plot
ggplotcv.subset = augment(crossvalidationmodel, data=crossvalidation.subset)
#generate the s-l plot
agetohealthcost_subset.plot <- ggplot(data = ggplotcv.subset, mapping=aes(x = .fitted, y = sqrt(abs(.resid)))) + geom_point(size = 1) + geom_smooth()
agetohealthcost_subset.plot
ggsave(agetohealthcost.plot, filename = "../results/agetohealthcost_subset.png")

```
After cross validation the next step is to plot the residuals against the predicted values to see if they look identically distributed. To do this we divide `age.interviewee` and `.fitted` into groups, and use quantile plots or QQ plots to see if the residuals in each group look identically distributed. The QQ plot help signficantly in trying to see if the residuals in each group look identically distributed. 

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=8, fig.height = 6, dpi = 100, fig.align = 'center'}
#generate a subset from the previous data use cut to group data
residuals.subset = mutate(ggplotcv.subset, pred = predict(crossvalidationmodel), resid = resid(crossvalidationmodel), age.interviewee.cat = cut_number(age.interviewee, n = 10))
residualsqq.subset <- mutate(residuals.subset, pred = predict(crossvalidationmodel), resid = resid(crossvalidationmodel), fitted.cat = cut_number(.fitted, n = 10))

#plot each of groups to compare
residuals_age.plot <- ggplot(data = residualsqq.subset, mapping=aes(sample = resid, color = age.interviewee.cat)) + stat_qq(distribution=qunif) + labs(x = 'quantiles', y = 'residual log healthcare', title = 'Quantile Plot, Residual Log Healthcare')
residuals_age.plot 
ggsave(residuals_age.plot, filename = "../results/residuals_age.png")


residuals_fitted.plot <- ggplot(data = residualsqq.subset, mapping = aes(sample = resid, color = fitted.cat)) + stat_qq(distribution=qunif) + labs(x = 'quantiles', y = 'residual log healthcare', title = 'Quantile Plot, Residual Log Healthcare')
residuals_fitted.plot
ggsave(residuals_fitted.plot, filename = "../results/residuals_age.png")
```
The two quantile plots for both age and fitted show similar distribution for all age groups across all quantiles addresses the first test for identical distribution. Another test for this is to organize the plots side by side using qq plots as below. 

```{r echo = FALSE, message = FALSE, warning = FALSE, fig.width=8, fig.height = 6, dpi = 100, fig.align = 'center'}

#Create qq plots to compare more clearly
QQ.df <- ddply(residualsqq.subset, 'age.interviewee.cat', Find.QQ, column.name ="resid", y = residualsqq.subset$resid)
QQ2.df <- ddply(residualsqq.subset, 'fitted.cat', Find.QQ, column.name = "resid", y = residualsqq.subset$resid)

qq_age.plot <- ggplot(data = QQ.df, mapping=aes(x = q1, y = q2)) + geom_point() + geom_abline() + facet_wrap('age.interviewee.cat', nrow = 2) + labs(title='QQ Plot, grouped vs pooled residuals')
qq_age.plot 
ggsave(qq_age.plot, filename = "../results/qq_age.png")

qq_fitted.plot <- ggplot(data = QQ2.df, mapping=aes(x = q1, y = q2)) + geom_point() + geom_abline() + facet_wrap('fitted.cat', nrow = 2) + labs(title='QQ Plot, grouped vs pooled residuals')
qq_fitted.plot
ggsave(qq_fitted.plot, filename = "../results/qq_fitted.png")

```
The QQ plot helps signficantly in determining if they residuals look identical and in this case, based on the plot generated, we see that the residuals in each group look identically distributed. 

#### Conclusion
The focus of this project was in two parts. The first part is building analysis tools through the creation of function to analyze demographic data. The second part was using the functions created to analyze the cost of healthcare as compared to age. The function created were based on the concept of implementing and testing machine learning. The first steps were to analyze the data utilizing linear models and following steps were testing the models using cross validation methods. The k-folds cross validation method is based on the train and test concept for machine learning modules and can be used to scale up this tool. This means that though the focus on this project was healthcare the same tools can be utilized for future work as listed below. The second part of this project was analyzing the cost of healthcare as compared to age using linear models and log transformations. The results show that the cost of healthcare increases with age with a sharper change after about 64 years old. The cross validation methods showed that the data sets were identically distributed providing veracity to the data. 

Future work from this project would be to implement ther the methodology to further analyze different facets of the demographic data reusing the same functions against different pairings or groups. For work utilizing these scripts would be to compare average incomes groups against average healthcare costs grouped by age to determine if costs are affected by both age, income, and suggested potential access to healthcare. A second comparison would be to compare lifestyle from cost of housing to food and region of living to cost of healthcare. These additional facets wold provide greater context as cost of living varies from region to region but also overall household costs can create a more wholistic picture. 

#### References

1. alongtest12, et al. “Creating a Sub Directory and Storing Files.” Stack Overflow, 1 May 1968, stackoverflow.com/questions/55682970/creating-a-sub-directory-and-storing-files. 

2. Avorn, Jerry, and Author AffiliationsFrom the Department of Social Medicine and Health Policy and the Division on Aging. “Benefit and Cost Analysis in Geriatric Care - Turning 

3. Age Discrimination into Health Policy: NEJM.” New England Journal of Medicine, www.nejm.org/doi/pdf/10.1056/NEJM198405173102005. 

4.niconico, et al. “Getting Path of an R Script.” Stack Overflow, 1 Sept. 1959, stackoverflow.com/questions/3452086/getting-path-of-an-r-script/35842176. 

5. R_and_Python_noobR_and_Python_noob. “Best Way to Install Required Packages in r.” Stack Overflow, 1 Nov. 1967, stackoverflow.com/questions/52574339/best-way-to-install-required-packages-in-r. 

6. Vaitkevicius, P V, et al. “Effects of Age and Aerobic Capacity on Arterial Stiffness in Healthy Adults.” Circulation, 1 Oct. 1993, www.ahajournals.org/doi/abs/10.1161/01.CIR.88.4.1456. 
